{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://blog.csdn.net/firparks/article/details/54563683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŸºäºä»¥ä¸‹è¯­æ–™å»ºç«‹è¯­è¨€æ¨¡å‹\n",
    "Father read Holy Bible.\n",
    "\n",
    "Mother read a text book.\n",
    "\n",
    "He read a book by grandpa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğ‘(\"Father read a book\")= 0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŠ ä¸€å¹³æ»‘åï¼š\n",
    "\n",
    "ğ‘(\"Father read a book\")=2/16Ã— 2/14Ã—  3/16Ã—  2/15Ã—  2/15  =0.00006  \n",
    "\n",
    "ğ‘(\"Grandpa read a book\" )=1/16Ã—1/14Ã— 3/16Ã—2/15Ã—2/15=0.000015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#å°†å¥å­å˜ä¸º\"BOSxxxxxEOS\"è¿™ç§å½¢å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#åˆ†è¯å¹¶ç»Ÿè®¡è¯é¢‘ï¼ŒåŠ ä¸€å¹³æ»‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#æ¯”è¾ƒä¸¤ä¸ªæ•°åˆ—ï¼ŒäºŒå…ƒè¯­æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#è®¡ç®—æ¦‚ç‡    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_ori=\"Father read Holy Bible. Mother read a text book. He read a book by grandpa.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_test=\"Father read a book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\David\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentence_modify2: BOSFather read Holy BibleEOSBOS Mother read a text bookEOSBOS He read a book by grandpaEOS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.632 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lists: ['BOS', 'Father', 'read', 'Holy', 'Bible', 'EOS', 'BOS', 'Mother', 'read', 'a', 'text', 'book', 'EOS', 'BOS', 'He', 'read', 'a', 'book', 'by', 'grandpa', 'EOS']\n",
      "\n",
      "dicts: {'BOS': 3, 'Father': 1, 'read': 3, 'Holy': 1, 'Bible': 1, 'EOS': 3, 'Mother': 1, 'a': 2, 'text': 1, 'book': 2, 'He': 1, 'by': 1, 'grandpa': 1}\n",
      "\n",
      "ori_list ['BOS', 'Father', 'read', 'Holy', 'Bible', 'EOS', 'BOS', 'Mother', 'read', 'a', 'text', 'book', 'EOS', 'BOS', 'He', 'read', 'a', 'book', 'by', 'grandpa', 'EOS']\n",
      "\n",
      "sentence_modify2: BOSFather read a bookEOS\n",
      "\n",
      "lists: ['BOS', 'Father', 'read', 'a', 'book', 'EOS']\n",
      "\n",
      "dicts: 0\n",
      "\n",
      "test_list ['BOS', 'Father', 'read', 'a', 'book', 'EOS']\n",
      "\n",
      "count_list [1, 1, 2, 1, 1, 0]\n",
      "\n",
      "NumOfOriDict: 13\n",
      "2 16\n",
      "2 14\n",
      "3 16\n",
      "2 15\n",
      "2 15\n",
      "\n",
      "\" Father read a book \"å‡ºç°çš„æ¦‚ç‡æ˜¯ï¼š0.000059524\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from _overlapped import NULL\n",
    "\n",
    "#å°†å¥å­å˜ä¸º\"BOSxxxxxEOS\"è¿™ç§å½¢å¼\n",
    "def reform(sentence):\n",
    "    #å¦‚æœæ˜¯ä»¥â€œã€‚â€ç»“æŸçš„åˆ™å°†â€œã€‚â€åˆ æ‰\n",
    "    if sentence.endswith(\".\"):\n",
    "        sentence=sentence[:-1]\n",
    "    #æ·»åŠ èµ·å§‹ç¬¦BOSå’Œç»ˆæ­¢ç¬¦EOS   \n",
    "    sentence_modify1=sentence.replace(\".\", \"EOSBOS\")\n",
    "    sentence_modify2=\"BOS\"+sentence_modify1+\"EOS\"\n",
    "    print('\\nsentence_modify2:',sentence_modify2)\n",
    "    return sentence_modify2\n",
    "\n",
    "\n",
    "#åˆ†è¯å¹¶ç»Ÿè®¡è¯é¢‘\n",
    "def segmentation(sentence,lists,dicts=NULL):\n",
    "    jieba.suggest_freq(\"BOS\", True)\n",
    "    jieba.suggest_freq(\"EOS\", True)\n",
    "    sentence = jieba.cut(sentence,HMM=False)\n",
    "    format_sentence=\",\".join(sentence)\n",
    "    #å°†è¯æŒ‰\",\"åˆ†å‰²åä¾æ¬¡å¡«å…¥æ•°ç»„word_list[]\n",
    "    lists=format_sentence.split(\",\")\n",
    "    #å»é™¤listsä¸­çš„ç©ºæ ¼\n",
    "    for i in lists:\n",
    "        if ' ' in lists:\n",
    "            lists.remove(' ')\n",
    "    #ç»Ÿè®¡è¯é¢‘ï¼Œå¦‚æœè¯åœ¨å­—å…¸word_dir{}ä¸­å‡ºç°è¿‡åˆ™+1ï¼Œæœªå‡ºç°åˆ™=1\n",
    "    if dicts!=NULL:\n",
    "        for word in lists:\n",
    "            if word not in dicts:\n",
    "                dicts[word]=1\n",
    "            else:\n",
    "                dicts[word]+=1               \n",
    "    print('\\nlists:',lists)\n",
    "    print('\\ndicts:',dicts)\n",
    "    return lists\n",
    "\n",
    "\n",
    "#æ¯”è¾ƒä¸¤ä¸ªæ•°åˆ—ï¼ŒäºŒå…ƒè¯­æ³•\n",
    "def compareList(ori_list,test_list):\n",
    "    #ç”³è¯·ç©ºé—´\n",
    "    count_list=[0]*(len(test_list))\n",
    "    #éå†æµ‹è¯•çš„å­—ç¬¦ä¸²\n",
    "    for i in range(0,len(test_list)-1):\n",
    "        #éå†è¯­æ–™å­—ç¬¦ä¸²ï¼Œä¸”å› ä¸ºæ˜¯äºŒå…ƒè¯­æ³•ï¼Œä¸ç”¨æ¯”è¾ƒè¯­æ–™å­—ç¬¦ä¸²çš„æœ€åä¸€ä¸ªå­—ç¬¦\n",
    "        for j in range(0,len(ori_list)-2):                \n",
    "            #å¦‚æœæµ‹è¯•çš„ç¬¬ä¸€ä¸ªè¯å’Œè¯­æ–™çš„ç¬¬ä¸€ä¸ªè¯ç›¸ç­‰åˆ™æ¯”è¾ƒç¬¬äºŒä¸ªè¯\n",
    "            if test_list[i]==ori_list[j]:\n",
    "                if test_list[i+1]==ori_list[j+1]:\n",
    "                    count_list[i]+=1\n",
    "    return count_list\n",
    "\n",
    "\n",
    "#è®¡ç®—æ¦‚ç‡    \n",
    "def probability(test_list,count_list,ori_dict):\n",
    "    flag=0\n",
    "    #ori_dictä¸åŒè¯çš„ä¸ªæ•°\n",
    "    NumOfOriDict = len(ori_dict)\n",
    "    print('\\nNumOfOriDict:',NumOfOriDict)\n",
    "    #æ¦‚ç‡å€¼ä¸ºp\n",
    "    p=1\n",
    "    for key in test_list[0:-1]: \n",
    "        #æ•°æ®å¹³æ»‘å¤„ç†ï¼šåŠ 1æ³• \n",
    "        p*=(float(count_list[flag]+1)/float(ori_dict[key] + NumOfOriDict))\n",
    "        print(count_list[flag]+1,ori_dict[key] + NumOfOriDict)\n",
    "        flag+=1\n",
    "    return p\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #è¯­æ–™å¥å­\n",
    "    sentence_ori=\"Father read Holy Bible. Mother read a text book. He read a book by grandpa.\"\n",
    "    ori_list=[]\n",
    "    ori_dict={}\n",
    "    sentence_ori_temp=\"\"\n",
    "\n",
    "    #æµ‹è¯•å¥å­\n",
    "    sentence_test=\"Father read a book\"\n",
    "    sentence_test_temp=\"\" \n",
    "    test_list=[]\n",
    "    count_list=[]\n",
    "    p=0\n",
    "\n",
    "    #åˆ†è¯å¹¶å°†ç»“æœå­˜å…¥ä¸€ä¸ªlistï¼Œè¯é¢‘ç»Ÿè®¡ç»“æœå­˜å…¥å­—å…¸\n",
    "    sentence_ori_temp=reform(sentence_ori)\n",
    "    ori_list=segmentation(sentence_ori_temp,ori_list,ori_dict)\n",
    "    print('\\nori_list',ori_list)\n",
    "\n",
    "    sentence_test_temp=reform(sentence_test)\n",
    "    test_list=segmentation(sentence_test_temp,test_list)\n",
    "    print('\\ntest_list',test_list)\n",
    "    \n",
    "    count_list=compareList(ori_list, test_list)\n",
    "    print('\\ncount_list',count_list)\n",
    "    \n",
    "    p=probability(test_list,count_list,ori_dict)\n",
    "\n",
    "    print('\\n\"',sentence_test,'\"å‡ºç°çš„æ¦‚ç‡æ˜¯ï¼š%.9f'% p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentence_modify2: BOSFather read Holy BibleEOSBOS Mother read a text bookEOSBOS He read a book by grandpaEOS\n",
      "\n",
      "lists: ['BOS', 'Father', 'read', 'Holy', 'Bible', 'EOS', 'BOS', 'Mother', 'read', 'a', 'text', 'book', 'EOS', 'BOS', 'He', 'read', 'a', 'book', 'by', 'grandpa', 'EOS']\n",
      "\n",
      "dicts: {'BOS': 3, 'Father': 1, 'read': 3, 'Holy': 1, 'Bible': 1, 'EOS': 3, 'Mother': 1, 'a': 2, 'text': 1, 'book': 2, 'He': 1, 'by': 1, 'grandpa': 1}\n",
      "\n",
      "ori_list ['BOS', 'Father', 'read', 'Holy', 'Bible', 'EOS', 'BOS', 'Mother', 'read', 'a', 'text', 'book', 'EOS', 'BOS', 'He', 'read', 'a', 'book', 'by', 'grandpa', 'EOS']\n",
      "\n",
      "sentence_modify2: BOSGrandpa read a bookEOS\n",
      "\n",
      "lists: ['BOS', 'Grandpa', 'read', 'a', 'book', 'EOS']\n",
      "\n",
      "dicts: 0\n",
      "\n",
      "test_list ['BOS', 'Grandpa', 'read', 'a', 'book', 'EOS']\n",
      "\n",
      "count_list [0, 0, 2, 1, 1, 0]\n",
      "\n",
      "NumOfOriDict: 13\n",
      "key: BOS\n",
      "0 3\n",
      "1 16\n",
      "p: 0.0625\n",
      "key: Grandpa\n",
      "0 1\n",
      "1 14\n",
      "p: 0.004464285714285714\n",
      "key: read\n",
      "2 3\n",
      "3 16\n",
      "p: 0.0008370535714285714\n",
      "key: a\n",
      "1 2\n",
      "2 15\n",
      "p: 0.00011160714285714285\n",
      "key: book\n",
      "1 2\n",
      "2 15\n",
      "p: 1.4880952380952381e-05\n",
      "\n",
      "\" Grandpa read a book \"å‡ºç°çš„æ¦‚ç‡æ˜¯ï¼š0.000014881\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from _overlapped import NULL\n",
    "\n",
    "#å°†å¥å­å˜ä¸º\"BOSxxxxxEOS\"è¿™ç§å½¢å¼\n",
    "def reform(sentence):\n",
    "    #å¦‚æœæ˜¯ä»¥â€œã€‚â€ç»“æŸçš„åˆ™å°†â€œã€‚â€åˆ æ‰\n",
    "    if sentence.endswith(\".\"):\n",
    "        sentence=sentence[:-1]\n",
    "    #æ·»åŠ èµ·å§‹ç¬¦BOSå’Œç»ˆæ­¢ç¬¦EOS   \n",
    "    sentence_modify1=sentence.replace(\".\", \"EOSBOS\")\n",
    "    sentence_modify2=\"BOS\"+sentence_modify1+\"EOS\"\n",
    "    print('\\nsentence_modify2:',sentence_modify2)\n",
    "    return sentence_modify2\n",
    "\n",
    "\n",
    "#åˆ†è¯å¹¶ç»Ÿè®¡è¯é¢‘\n",
    "def segmentation(sentence,lists,dicts=NULL):\n",
    "    jieba.suggest_freq(\"BOS\", True)\n",
    "    jieba.suggest_freq(\"EOS\", True)\n",
    "    sentence = jieba.cut(sentence,HMM=False)\n",
    "    format_sentence=\",\".join(sentence)\n",
    "    #å°†è¯æŒ‰\",\"åˆ†å‰²åä¾æ¬¡å¡«å…¥æ•°ç»„word_list[]\n",
    "    lists=format_sentence.split(\",\")\n",
    "    #å»é™¤listsä¸­çš„ç©ºæ ¼\n",
    "    for i in lists:\n",
    "        if ' ' in lists:\n",
    "            lists.remove(' ')\n",
    "    #ç»Ÿè®¡è¯é¢‘ï¼Œå¦‚æœè¯åœ¨å­—å…¸word_dir{}ä¸­å‡ºç°è¿‡åˆ™+1ï¼Œæœªå‡ºç°åˆ™=1\n",
    "    if dicts!=NULL:\n",
    "        for word in lists:\n",
    "            if word not in dicts:\n",
    "                dicts[word]=1\n",
    "            else:\n",
    "                dicts[word]+=1               \n",
    "    print('\\nlists:',lists)\n",
    "    print('\\ndicts:',dicts)\n",
    "    return lists\n",
    "\n",
    "\n",
    "#æ¯”è¾ƒä¸¤ä¸ªæ•°åˆ—ï¼ŒäºŒå…ƒè¯­æ³•\n",
    "def compareList(ori_list,test_list):\n",
    "    #ç”³è¯·ç©ºé—´\n",
    "    count_list=[0]*(len(test_list))\n",
    "    #éå†æµ‹è¯•çš„å­—ç¬¦ä¸²\n",
    "    for i in range(0,len(test_list)-1):\n",
    "        #éå†è¯­æ–™å­—ç¬¦ä¸²ï¼Œä¸”å› ä¸ºæ˜¯äºŒå…ƒè¯­æ³•ï¼Œä¸ç”¨æ¯”è¾ƒè¯­æ–™å­—ç¬¦ä¸²çš„æœ€åä¸€ä¸ªå­—ç¬¦\n",
    "        for j in range(0,len(ori_list)-2):                \n",
    "            #å¦‚æœæµ‹è¯•çš„ç¬¬ä¸€ä¸ªè¯å’Œè¯­æ–™çš„ç¬¬ä¸€ä¸ªè¯ç›¸ç­‰åˆ™æ¯”è¾ƒç¬¬äºŒä¸ªè¯\n",
    "            if test_list[i]==ori_list[j]:\n",
    "                if test_list[i+1]==ori_list[j+1]:\n",
    "                    count_list[i]+=1\n",
    "    return count_list\n",
    "\n",
    "\n",
    "#è®¡ç®—æ¦‚ç‡    \n",
    "def probability(test_list,count_list,ori_dict):\n",
    "    flag=0\n",
    "    #ori_dictä¸åŒè¯çš„ä¸ªæ•°\n",
    "    NumOfOriDict = len(ori_dict)\n",
    "    print('\\nNumOfOriDict:',NumOfOriDict)\n",
    "    #æ¦‚ç‡å€¼ä¸ºp\n",
    "    p=1\n",
    "    for key in test_list[0:-1]: \n",
    "        #æ•°æ®å¹³æ»‘å¤„ç†ï¼šåŠ 1æ³• \n",
    "        print('key:',key)\n",
    "        if key not in ori_dict: # å¦‚æœkeyä¸å†ori_dictä¸­ï¼Œori_dict[key]ä¼šæŠ¥é”™\n",
    "            ori_dict[key]=1\n",
    "        p*=(float(count_list[flag]+1)/float(ori_dict[key] + NumOfOriDict))\n",
    "        print(count_list[flag],ori_dict[key])\n",
    "        print(count_list[flag]+1,ori_dict[key] + NumOfOriDict)\n",
    "        print('p:',p)\n",
    "        flag+=1\n",
    "    return p\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #è¯­æ–™å¥å­\n",
    "    sentence_ori=\"Father read Holy Bible. Mother read a text book. He read a book by grandpa.\"\n",
    "    ori_list=[]\n",
    "    ori_dict={}\n",
    "    sentence_ori_temp=\"\"\n",
    "\n",
    "    #æµ‹è¯•å¥å­\n",
    "    sentence_test=\"Grandpa read a book\"\n",
    "    sentence_test_temp=\"\" \n",
    "    test_list=[]\n",
    "    count_list=[]\n",
    "    p=0\n",
    "\n",
    "    #åˆ†è¯å¹¶å°†ç»“æœå­˜å…¥ä¸€ä¸ªlistï¼Œè¯é¢‘ç»Ÿè®¡ç»“æœå­˜å…¥å­—å…¸\n",
    "    sentence_ori_temp=reform(sentence_ori)\n",
    "    ori_list=segmentation(sentence_ori_temp,ori_list,ori_dict)\n",
    "    print('\\nori_list',ori_list)\n",
    "\n",
    "    sentence_test_temp=reform(sentence_test)\n",
    "    test_list=segmentation(sentence_test_temp,test_list)\n",
    "    print('\\ntest_list',test_list)\n",
    "    \n",
    "    count_list=compareList(ori_list, test_list)\n",
    "    print('\\ncount_list',count_list)\n",
    "    \n",
    "    p=probability(test_list,count_list,ori_dict)\n",
    "\n",
    "    print('\\n\"',sentence_test,'\"å‡ºç°çš„æ¦‚ç‡æ˜¯ï¼š%.9f'% p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
