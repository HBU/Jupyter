{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "start_c={}#开始概率，就是一个字典，state:chance=Word/lines\n",
    "transport_c={}#转移概率，是字典：字典，state:{state:num,state:num....}   num=num(state1)/num(statess)\n",
    "emit_c={}#发射概率，也是一个字典，state:{word:num,word,num}  num=num(word)/num(words)\n",
    "Count_dic = {}  # 一个属性下的所有单词，为了求解emit\n",
    "state_list = ['Ag', 'a', 'ad', 'an', 'Bg', 'b', 'c', 'Dg',\n",
    "\t\t\t  'd', 'e', 'f', 'h', 'i', 'j', 'k', 'l',\n",
    "\t\t\t  'Mg', 'm', 'Ng', 'n', 'nr', 'ns', 'nt', 'nx',\n",
    "\t\t\t  'nz', 'o', 'p', 'q', 'Rg', 'r', 's','na',\n",
    "\t\t\t  'Tg', 't','u', 'Vg', 'v', 'vd', 'vn','vvn',\n",
    "\t\t\t  'w', 'Yg', 'y', 'z']\n",
    "lineCount=-1#句子总数，为了求出开始概率\n",
    "for state0 in state_list:\n",
    "    transport_c[state0]={}\n",
    "    for state1 in state_list:\n",
    "        transport_c[state0][state1]=0.0\n",
    "    emit_c[state0]={}\n",
    "    start_c[state0]=0.0\n",
    "vocabs=[]\n",
    "classify=[]\n",
    "class_count={}\n",
    "for state in state_list:\n",
    "    class_count[state]=0.0\n",
    "with open('corpus_POS.txt') as filess:\n",
    "    for line in filess:  #一次处理全部的行？？列表可能会影响效率？？\n",
    "        line=line.strip()\n",
    "        if not line:continue\n",
    "        lineCount+=1#应该在有内容的行处加 1\n",
    "        words=line.split(\" \")#分解为多个单词\n",
    "        for word in words:\n",
    "            position=word.index('/')  #如果是[中国人民/n]\n",
    "            if '[' in word and ']' in word:\n",
    "                vocabs.append(word[1:position])\n",
    "                vocabs.append(word[position+1:-1])\n",
    "                break\n",
    "            if  '[' in word:\n",
    "                vocabs.append(word[1:position])\n",
    "                classify.append(word[position+1:])\n",
    "                break\n",
    "            if ']' in  word:\n",
    "                vocabs.append(word[:position])\n",
    "                classify.append(word[position+1:-1])\n",
    "                break\n",
    "            vocabs.append(word[:position])\n",
    "            classify.append(word[position+1:])\n",
    "\n",
    "        if  len(vocabs)!=len(classify):\n",
    "            print('词汇数量与类别数量不一致')\n",
    "            break  #不一致退出程序\n",
    "            # start_c = {}  # 开始概率，就是一个字典，state:chance=Word/lines\n",
    "            # transport_c = {}  # 转移概率，是字典：字典，state:{state:num,state:num....}   num=num(state1)/num(statess)\n",
    "            # emit_c = {}  # 发射概率，也是一个字典，state:{word:num,word,num}  num=num(word)/num(words)\n",
    "        else:\n",
    "            for n in range(0,len(vocabs)):\n",
    "                class_count[classify[n]]+=1.0\n",
    "                if vocabs[n] in emit_c[classify[n]]:\n",
    "                    emit_c[classify[n]][vocabs[n]] += 1.0\n",
    "                else:\n",
    "                    emit_c[classify[n]][vocabs[n]] = 1.0\n",
    "                if n==0:\n",
    "                    start_c[classify[n]] += 1.0\n",
    "                else:\n",
    "                    transport_c[classify[n-1]][classify[n]]+=1.0\n",
    "        vocabs = []\n",
    "        classify = []\n",
    "for state in state_list:\n",
    "    start_c[state]=start_c[state]*1.0/lineCount\n",
    "    for li in emit_c[state]:\n",
    "        emit_c[state][li]=emit_c[state][li]/class_count[state]\n",
    "    for li in transport_c[state]:\n",
    "        transport_c[state][li]=transport_c[state][li]/class_count[state]\n",
    "file0=open('start.txt','w',encoding='utf8')\n",
    "file0.write(str(start_c))\n",
    "file1=open('tran.txt','w',encoding='utf8')\n",
    "file1.write(str(transport_c))\n",
    "file2=open('emit.txt','w',encoding='utf8')\n",
    "file2.write(str(emit_c))\n",
    "file0.close()\n",
    "file1.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
